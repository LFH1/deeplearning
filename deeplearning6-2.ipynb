{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom d2l import torch as d2l\n\ndef corr2d(X, K):  #@save\n    \"\"\"计算二维互相关运算\"\"\"\n    h, w = K.shape\n    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n    for i in range(Y.shape[0]):\n        for j in range(Y.shape[1]):\n            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n    return Y\n\n# 如果将本节中举例的卷积核K应用于X，会发生什么情况？\nX = torch.eye(8)\nK = torch.tensor([[1.0, -1.0]])\nY = corr2d(X, K)\nprint(Y)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T09:18:08.963337Z","iopub.execute_input":"2024-06-28T09:18:08.963791Z","iopub.status.idle":"2024-06-28T09:18:08.976755Z","shell.execute_reply.started":"2024-06-28T09:18:08.963759Z","shell.execute_reply":"2024-06-28T09:18:08.975627Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"tensor([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n        [-1.,  1.,  0.,  0.,  0.,  0.,  0.],\n        [ 0., -1.,  1.,  0.,  0.,  0.,  0.],\n        [ 0.,  0., -1.,  1.,  0.,  0.,  0.],\n        [ 0.,  0.,  0., -1.,  1.,  0.,  0.],\n        [ 0.,  0.,  0.,  0., -1.,  1.,  0.],\n        [ 0.,  0.,  0.,  0.,  0., -1.,  1.],\n        [ 0.,  0.,  0.,  0.,  0.,  0., -1.]])\n","output_type":"stream"}]},{"cell_type":"code","source":"X = torch.eye(8).T\nK = torch.tensor([[1.0, -1.0]])\nY = corr2d(X, K)\nprint(Y)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T09:06:33.467243Z","iopub.execute_input":"2024-06-28T09:06:33.467660Z","iopub.status.idle":"2024-06-28T09:06:33.476886Z","shell.execute_reply.started":"2024-06-28T09:06:33.467616Z","shell.execute_reply":"2024-06-28T09:06:33.475784Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"tensor([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n        [-1.,  1.,  0.,  0.,  0.,  0.,  0.],\n        [ 0., -1.,  1.,  0.,  0.,  0.,  0.],\n        [ 0.,  0., -1.,  1.,  0.,  0.,  0.],\n        [ 0.,  0.,  0., -1.,  1.,  0.,  0.],\n        [ 0.,  0.,  0.,  0., -1.,  1.,  0.],\n        [ 0.,  0.,  0.,  0.,  0., -1.,  1.],\n        [ 0.,  0.,  0.,  0.,  0.,  0., -1.]])\n","output_type":"stream"}]},{"cell_type":"code","source":"X = torch.eye(8)\nK = torch.tensor([[1.0, -1.0]]).T\nY = corr2d(X, K)\nprint(Y)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T09:10:59.136854Z","iopub.execute_input":"2024-06-28T09:10:59.137297Z","iopub.status.idle":"2024-06-28T09:10:59.146988Z","shell.execute_reply.started":"2024-06-28T09:10:59.137267Z","shell.execute_reply":"2024-06-28T09:10:59.145833Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"tensor([[ 1., -1.,  0.,  0.,  0.,  0.,  0.,  0.],\n        [ 0.,  1., -1.,  0.,  0.,  0.,  0.,  0.],\n        [ 0.,  0.,  1., -1.,  0.,  0.,  0.,  0.],\n        [ 0.,  0.,  0.,  1., -1.,  0.,  0.,  0.],\n        [ 0.,  0.,  0.,  0.,  1., -1.,  0.,  0.],\n        [ 0.,  0.,  0.,  0.,  0.,  1., -1.,  0.],\n        [ 0.,  0.,  0.,  0.,  0.,  0.,  1., -1.]])\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom d2l import torch as d2l\n\ndef corr2d(X, K):  #@save\n    \"\"\"计算二维互相关运算\"\"\"\n    h, w = K.shape\n    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n    for i in range(Y.shape[0]):\n        for j in range(Y.shape[1]):\n            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n    return Y\n\nX = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\nK = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n\nX = torch.ones((6, 8))\nX[:, 2:6] = 0\n\nK = torch.tensor([[1.0, -1.0]])\nY = corr2d(X, K)\n\nclass Conv2D(nn.Module):\n    def __init__(self, kernel_size):\n        super().__init__()\n        self.weight = nn.Parameter(torch.rand(kernel_size))\n        self.bias = nn.Parameter(torch.zeros(1))\n\n    def forward(self, x):\n        return corr2d(x, self.weight) + self.bias\n# 构造一个二维卷积层，它具有1个输出通道和形状为（1，2）的卷积核\nconv2d = nn.Conv2d(1,1, kernel_size=(1, 2), bias=False)\n\n# 这个二维卷积层使用四维输入和输出格式（批量大小、通道、高度、宽度），\n# 其中批量大小和通道数都为1\nX = X.reshape((1, 1, 6, 8))\nY = Y.reshape((1, 1, 6, 7))\nlr = 3e-2  # 学习率\n\nfor i in range(10):\n    Y_hat = conv2d(X)\n    l = (Y_hat - Y) ** 2\n    conv2d.zero_grad()\n    l.sum().backward()\n    # 迭代卷积核\n    conv2d.weight.data[:] -= lr * conv2d.weight.grad\n    if (i + 1) % 2 == 0:\n        print(f'epoch {i+1}, loss {l.sum():.3f}')\nconv2d = Conv2D(kernel_size=(1, 2))\n\ntry:\n  for i in range(10):\n    Y_hat = conv2d(X)\n    l = (Y_hat - Y) ** 2\n    conv2d.zero_grad()\n    l.sum().backward()\n    # 迭代卷积核\n    conv2d.weight.data[:] -= lr * conv2d.weight.grad\n    if (i + 1) % 2 == 0:\n        print(f'epoch {i+1}, loss {l.sum():.3f}')\nexcept Exception as e:\n    print(e)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T09:25:39.181175Z","iopub.execute_input":"2024-06-28T09:25:39.181591Z","iopub.status.idle":"2024-06-28T09:25:39.248335Z","shell.execute_reply.started":"2024-06-28T09:25:39.181557Z","shell.execute_reply":"2024-06-28T09:25:39.247208Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"epoch 2, loss 12.631\nepoch 4, loss 4.365\nepoch 6, loss 1.652\nepoch 8, loss 0.654\nepoch 10, loss 0.264\nThe size of tensor a (0) must match the size of tensor b (7) at non-singleton dimension 3\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom d2l import torch as d2l\n\ndef conv2d_by_mul(X, K):\n    # 获取卷积核大小\n    h, w = K.shape\n    # 计算输出图像大小\n    outh = X.shape[0] - h + 1\n    outw = X.shape[1] - w + 1\n    # 调整卷积核形状以便做乘法\n    K = K.reshape(-1, 1)\n    # 将输入图像切成卷积核大小的块，打平成一维，存放在列表 Y 中\n    Y = []\n    for i in range(outh):\n        for j in range(outw):\n            Y.append(X[i:i + h, j:j + w].reshape(-1))\n    # 将列表 Y 转为张量，每行代表一块的打平结果\n    Y = torch.stack(Y, 0)\n    # 用矩阵乘法表示互相关运算\n    res = (torch.matmul(Y, K)).reshape(outh, outw)\n    # 返回输出结果\n    return res\nX = torch.ones((2, 3))\nX[:,1]=0\nprint(X)\nK = torch.ones((2, 3))\nconv2d_by_mul(X, K)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T09:27:15.063805Z","iopub.execute_input":"2024-06-28T09:27:15.064228Z","iopub.status.idle":"2024-06-28T09:27:15.083801Z","shell.execute_reply.started":"2024-06-28T09:27:15.064195Z","shell.execute_reply":"2024-06-28T09:27:15.082576Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"tensor([[1., 0., 1.],\n        [1., 0., 1.]])\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"tensor([[4.]])"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}