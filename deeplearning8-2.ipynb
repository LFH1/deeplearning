{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-07T16:19:16.562249Z","iopub.execute_input":"2024-07-07T16:19:16.562681Z","iopub.status.idle":"2024-07-07T16:19:17.732128Z","shell.execute_reply.started":"2024-07-07T16:19:16.562639Z","shell.execute_reply":"2024-07-07T16:19:17.731104Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import collections\nimport re\nfrom d2l import torch as d2l","metadata":{"execution":{"iopub.status.busy":"2024-07-07T16:20:47.633988Z","iopub.execute_input":"2024-07-07T16:20:47.634433Z","iopub.status.idle":"2024-07-07T16:20:52.847762Z","shell.execute_reply.started":"2024-07-07T16:20:47.634396Z","shell.execute_reply":"2024-07-07T16:20:52.846542Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#@save\nd2l.DATA_HUB['time_machine'] = (d2l.DATA_URL + 'timemachine.txt',\n                                '090b5e7e70c295757f55df93cb0a180b9691891a')\n\ndef read_time_machine():  #@save\n    \"\"\"将时间机器数据集加载到文本行的列表中\"\"\"\n    with open(d2l.download('time_machine'), 'r') as f:\n        lines = f.readlines()\n    return [re.sub('[^A-Za-z]+', ' ', line).strip().lower() for line in lines]\n\nlines = read_time_machine()\nprint(f'# 文本总行数: {len(lines)}')\nprint(lines[0])\nprint(lines[10])","metadata":{"execution":{"iopub.status.busy":"2024-07-07T16:21:17.344268Z","iopub.execute_input":"2024-07-07T16:21:17.344940Z","iopub.status.idle":"2024-07-07T16:21:17.529369Z","shell.execute_reply.started":"2024-07-07T16:21:17.344904Z","shell.execute_reply":"2024-07-07T16:21:17.528278Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Downloading ../data/timemachine.txt from http://d2l-data.s3-accelerate.amazonaws.com/timemachine.txt...\n# 文本总行数: 3221\nthe time machine by h g wells\ntwinkled and his usually pale face was flushed and animated the\n","output_type":"stream"}]},{"cell_type":"code","source":"def tokenize(lines, token='word'):  #@save\n    \"\"\"将文本行拆分为单词或字符词元\"\"\"\n    if token == 'word':\n        return [line.split() for line in lines]\n    elif token == 'char':\n        return [list(line) for line in lines]\n    else:\n        print('错误：未知词元类型：' + token)\n\ntokens = tokenize(lines)\nfor i in range(11):\n    print(tokens[i])","metadata":{"execution":{"iopub.status.busy":"2024-07-07T16:24:49.867340Z","iopub.execute_input":"2024-07-07T16:24:49.867790Z","iopub.status.idle":"2024-07-07T16:24:49.881083Z","shell.execute_reply.started":"2024-07-07T16:24:49.867757Z","shell.execute_reply":"2024-07-07T16:24:49.879898Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"['the', 'time', 'machine', 'by', 'h', 'g', 'wells']\n[]\n[]\n[]\n[]\n['i']\n[]\n[]\n['the', 'time', 'traveller', 'for', 'so', 'it', 'will', 'be', 'convenient', 'to', 'speak', 'of', 'him']\n['was', 'expounding', 'a', 'recondite', 'matter', 'to', 'us', 'his', 'grey', 'eyes', 'shone', 'and']\n['twinkled', 'and', 'his', 'usually', 'pale', 'face', 'was', 'flushed', 'and', 'animated', 'the']\n","output_type":"stream"}]},{"cell_type":"code","source":"class Vocab:  #@save\n    \"\"\"文本词表\"\"\"\n    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n        if tokens is None:\n            tokens = []\n        if reserved_tokens is None:\n            reserved_tokens = []\n        # 按出现频率排序\n        counter = count_corpus(tokens)\n        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],\n                                   reverse=True)\n        # 未知词元的索引为0\n        self.idx_to_token = ['<unk>'] + reserved_tokens\n        self.token_to_idx = {token: idx\n                             for idx, token in enumerate(self.idx_to_token)}\n        for token, freq in self._token_freqs:\n            if freq < min_freq:\n                break\n            if token not in self.token_to_idx:\n                self.idx_to_token.append(token)\n                self.token_to_idx[token] = len(self.idx_to_token) - 1\n\n    def __len__(self):\n        return len(self.idx_to_token)\n\n    def __getitem__(self, tokens):\n        if not isinstance(tokens, (list, tuple)):\n            return self.token_to_idx.get(tokens, self.unk)\n        return [self.__getitem__(token) for token in tokens]\n\n    def to_tokens(self, indices):\n        if not isinstance(indices, (list, tuple)):\n            return self.idx_to_token[indices]\n        return [self.idx_to_token[index] for index in indices]\n\n    @property\n    def unk(self):  # 未知词元的索引为0\n        return 0\n\n    @property\n    def token_freqs(self):\n        return self._token_freqs\n\ndef count_corpus(tokens):  #@save\n    \"\"\"统计词元的频率\"\"\"\n    # 这里的tokens是1D列表或2D列表\n    if len(tokens) == 0 or isinstance(tokens[0], list):\n        # 将词元列表展平成一个列表\n        tokens = [token for line in tokens for token in line]\n    return collections.Counter(tokens)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T16:26:56.284533Z","iopub.execute_input":"2024-07-07T16:26:56.285246Z","iopub.status.idle":"2024-07-07T16:26:56.300785Z","shell.execute_reply.started":"2024-07-07T16:26:56.285211Z","shell.execute_reply":"2024-07-07T16:26:56.299442Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"vocab = Vocab(tokens)\nprint(list(vocab.token_to_idx.items())[:10])","metadata":{"execution":{"iopub.status.busy":"2024-07-07T16:27:02.226313Z","iopub.execute_input":"2024-07-07T16:27:02.226720Z","iopub.status.idle":"2024-07-07T16:27:02.244577Z","shell.execute_reply.started":"2024-07-07T16:27:02.226689Z","shell.execute_reply":"2024-07-07T16:27:02.243420Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"[('<unk>', 0), ('the', 1), ('i', 2), ('and', 3), ('of', 4), ('a', 5), ('to', 6), ('was', 7), ('in', 8), ('that', 9)]\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in [0, 10]:\n    print('文本:', tokens[i])\n    print('索引:', vocab[tokens[i]])","metadata":{"execution":{"iopub.status.busy":"2024-07-07T16:28:20.071858Z","iopub.execute_input":"2024-07-07T16:28:20.072275Z","iopub.status.idle":"2024-07-07T16:28:20.078635Z","shell.execute_reply.started":"2024-07-07T16:28:20.072242Z","shell.execute_reply":"2024-07-07T16:28:20.077384Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"文本: ['the', 'time', 'machine', 'by', 'h', 'g', 'wells']\n索引: [1, 19, 50, 40, 2183, 2184, 400]\n文本: ['twinkled', 'and', 'his', 'usually', 'pale', 'face', 'was', 'flushed', 'and', 'animated', 'the']\n索引: [2186, 3, 25, 1044, 362, 113, 7, 1421, 3, 1045, 1]\n","output_type":"stream"}]},{"cell_type":"code","source":"def load_corpus_time_machine(max_tokens=-1):  #@save\n    \"\"\"返回时光机器数据集的词元索引列表和词表\"\"\"\n    lines = read_time_machine()\n    tokens = tokenize(lines, 'word')\n    vocab = Vocab(tokens,min_freq=2)\n    # 因为时光机器数据集中的每个文本行不一定是一个句子或一个段落，\n    # 所以将所有文本行展平到一个列表中\n    corpus = [vocab[token] for line in tokens for token in line]\n    if max_tokens > 0:\n        corpus = corpus[:max_tokens]\n    return corpus, vocab\n\ncorpus, vocab = load_corpus_time_machine()\nlen(corpus), len(vocab)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T16:36:47.609390Z","iopub.execute_input":"2024-07-07T16:36:47.610430Z","iopub.status.idle":"2024-07-07T16:36:47.693682Z","shell.execute_reply.started":"2024-07-07T16:36:47.610392Z","shell.execute_reply":"2024-07-07T16:36:47.692533Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(32775, 2183)"},"metadata":{}}]}]}