{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-08T15:33:32.966786Z","iopub.execute_input":"2024-07-08T15:33:32.967772Z","iopub.status.idle":"2024-07-08T15:33:34.292870Z","shell.execute_reply.started":"2024-07-08T15:33:32.967734Z","shell.execute_reply":"2024-07-08T15:33:34.291743Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import math\nimport pandas as pd\nimport torch\nfrom torch import nn\nfrom d2l import torch as d2l","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:05:39.973221Z","iopub.execute_input":"2024-07-08T17:05:39.974498Z","iopub.status.idle":"2024-07-08T17:05:39.979786Z","shell.execute_reply.started":"2024-07-08T17:05:39.974456Z","shell.execute_reply":"2024-07-08T17:05:39.978468Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"#@save\nclass PositionWiseFFN(nn.Module):\n    \"\"\"基于位置的前馈网络\"\"\"\n    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs,\n                 **kwargs):\n        super(PositionWiseFFN, self).__init__(**kwargs)\n        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n        self.relu = nn.ReLU()\n        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n\n    def forward(self, X):\n        return self.dense2(self.relu(self.dense1(X)))","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:06:01.908991Z","iopub.execute_input":"2024-07-08T17:06:01.909421Z","iopub.status.idle":"2024-07-08T17:06:01.916657Z","shell.execute_reply.started":"2024-07-08T17:06:01.909391Z","shell.execute_reply":"2024-07-08T17:06:01.915461Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"ffn = PositionWiseFFN(4, 4, 8)\nffn.eval()\nffn(torch.ones((2, 3, 4)))[0]","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:06:04.220124Z","iopub.execute_input":"2024-07-08T17:06:04.220827Z","iopub.status.idle":"2024-07-08T17:06:04.236484Z","shell.execute_reply.started":"2024-07-08T17:06:04.220795Z","shell.execute_reply":"2024-07-08T17:06:04.235065Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"tensor([[-0.0664,  0.2845, -0.4812, -0.5603,  0.4591,  0.4092,  0.6275, -0.1442],\n        [-0.0664,  0.2845, -0.4812, -0.5603,  0.4591,  0.4092,  0.6275, -0.1442],\n        [-0.0664,  0.2845, -0.4812, -0.5603,  0.4591,  0.4092,  0.6275, -0.1442]],\n       grad_fn=<SelectBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"ln = nn.LayerNorm(2)\nbn = nn.BatchNorm1d(2)\nX = torch.tensor([[1, 2], [2, 3]], dtype=torch.float32)\n# 在训练模式下计算X的均值和方差\nprint('layer norm:', ln(X), '\\nbatch norm:', bn(X))","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:06:15.933891Z","iopub.execute_input":"2024-07-08T17:06:15.934345Z","iopub.status.idle":"2024-07-08T17:06:15.955587Z","shell.execute_reply.started":"2024-07-08T17:06:15.934310Z","shell.execute_reply":"2024-07-08T17:06:15.953977Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"layer norm: tensor([[-1.0000,  1.0000],\n        [-1.0000,  1.0000]], grad_fn=<NativeLayerNormBackward0>) \nbatch norm: tensor([[-1.0000, -1.0000],\n        [ 1.0000,  1.0000]], grad_fn=<NativeBatchNormBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"#@save\nclass AddNorm(nn.Module):\n    \"\"\"残差连接后进行层规范化\"\"\"\n    def __init__(self, normalized_shape, dropout, **kwargs):\n        super(AddNorm, self).__init__(**kwargs)\n        self.dropout = nn.Dropout(dropout)\n        self.ln = nn.LayerNorm(normalized_shape)\n\n    def forward(self, X, Y):\n        return self.ln(self.dropout(Y) + X)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:09:01.678389Z","iopub.execute_input":"2024-07-08T17:09:01.678834Z","iopub.status.idle":"2024-07-08T17:09:01.685871Z","shell.execute_reply.started":"2024-07-08T17:09:01.678806Z","shell.execute_reply":"2024-07-08T17:09:01.684554Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"add_norm = AddNorm([3, 4], 0.5)\nadd_norm.eval()\nadd_norm(torch.ones((2, 3, 4)), torch.ones((2, 3, 4))).shape","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:09:08.434077Z","iopub.execute_input":"2024-07-08T17:09:08.434868Z","iopub.status.idle":"2024-07-08T17:09:08.444218Z","shell.execute_reply.started":"2024-07-08T17:09:08.434820Z","shell.execute_reply":"2024-07-08T17:09:08.443334Z"},"trusted":true},"execution_count":72,"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"torch.Size([2, 3, 4])"},"metadata":{}}]},{"cell_type":"code","source":"#@save\nclass EncoderBlock(nn.Module):\n    \"\"\"Transformer编码器块\"\"\"\n    def __init__(self, key_size, query_size, value_size, num_hiddens,\n                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n                 dropout, use_bias=False, **kwargs):\n        super(EncoderBlock, self).__init__(**kwargs)\n        self.attention = d2l.MultiHeadAttention(\n            key_size, query_size, value_size, num_hiddens, num_heads, dropout,\n            use_bias)\n        self.addnorm1 = AddNorm(norm_shape, dropout)\n        self.ffn = PositionWiseFFN(\n            ffn_num_input, ffn_num_hiddens, num_hiddens)\n        self.addnorm2 = AddNorm(norm_shape, dropout)\n\n    def forward(self, X, valid_lens):\n        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))\n        return self.addnorm2(Y, self.ffn(Y))","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:09:35.263695Z","iopub.execute_input":"2024-07-08T17:09:35.264099Z","iopub.status.idle":"2024-07-08T17:09:35.272053Z","shell.execute_reply.started":"2024-07-08T17:09:35.264060Z","shell.execute_reply":"2024-07-08T17:09:35.270881Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"X = torch.ones((2, 100, 24))\nvalid_lens = torch.tensor([3, 2])\nencoder_blk = EncoderBlock(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5)\nencoder_blk.eval()\nencoder_blk(X, valid_lens).shape","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:09:38.175839Z","iopub.execute_input":"2024-07-08T17:09:38.176233Z","iopub.status.idle":"2024-07-08T17:09:38.229501Z","shell.execute_reply.started":"2024-07-08T17:09:38.176202Z","shell.execute_reply":"2024-07-08T17:09:38.227864Z"},"trusted":true},"execution_count":76,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[76], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m24\u001b[39m))\n\u001b[1;32m      2\u001b[0m valid_lens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m encoder_blk \u001b[38;5;241m=\u001b[39m \u001b[43mEncoderBlock\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m48\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m encoder_blk\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      5\u001b[0m encoder_blk(X, valid_lens)\u001b[38;5;241m.\u001b[39mshape\n","Cell \u001b[0;32mIn[75], line 8\u001b[0m, in \u001b[0;36mEncoderBlock.__init__\u001b[0;34m(self, key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, dropout, use_bias, **kwargs)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key_size, query_size, value_size, num_hiddens,\n\u001b[1;32m      5\u001b[0m              norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n\u001b[1;32m      6\u001b[0m              dropout, use_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28msuper\u001b[39m(EncoderBlock, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention \u001b[38;5;241m=\u001b[39m \u001b[43md2l\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMultiHeadAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_hiddens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddnorm1 \u001b[38;5;241m=\u001b[39m AddNorm(norm_shape, dropout)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn \u001b[38;5;241m=\u001b[39m PositionWiseFFN(\n\u001b[1;32m     13\u001b[0m         ffn_num_input, ffn_num_hiddens, num_hiddens)\n","\u001b[0;31mTypeError\u001b[0m: MultiHeadAttention.__init__() takes from 4 to 5 positional arguments but 8 were given"],"ename":"TypeError","evalue":"MultiHeadAttention.__init__() takes from 4 to 5 positional arguments but 8 were given","output_type":"error"}]},{"cell_type":"code","source":"#@save\nclass TransformerEncoder(d2l.Encoder):\n    \"\"\"Transformer编码器\"\"\"\n    def __init__(self, vocab_size, key_size, query_size, value_size,\n                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n                 num_heads, num_layers, dropout, use_bias=False, **kwargs):\n        super(TransformerEncoder, self).__init__(**kwargs)\n        self.num_hiddens = num_hiddens\n        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n        self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)\n        self.blks = nn.Sequential()\n        for i in range(num_layers):\n            self.blks.add_module(\"block\"+str(i),\n                EncoderBlock(key_size, query_size, value_size, num_hiddens,\n                             norm_shape, ffn_num_input, ffn_num_hiddens,\n                             num_heads, dropout, use_bias))\n\n    def forward(self, X, valid_lens, *args):\n        # 因为位置编码值在-1和1之间，\n        # 因此嵌入值乘以嵌入维度的平方根进行缩放，\n        # 然后再与位置编码相加。\n        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n        self.attention_weights = [None] * len(self.blks)\n        for i, blk in enumerate(self.blks):\n            X = blk(X, valid_lens)\n            self.attention_weights[\n                i] = blk.attention.attention.attention_weights\n        return X","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:09:54.077551Z","iopub.execute_input":"2024-07-08T17:09:54.077947Z","iopub.status.idle":"2024-07-08T17:09:54.087799Z","shell.execute_reply.started":"2024-07-08T17:09:54.077917Z","shell.execute_reply":"2024-07-08T17:09:54.086439Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"encoder = TransformerEncoder(\n    200, 24, 24, 24, 24, [100, 24], 24, 48, 8, 2, 0.5)\nencoder.eval()\nencoder(torch.ones((2, 100), dtype=torch.long), valid_lens).shape","metadata":{"execution":{"iopub.status.busy":"2024-07-08T17:10:01.503388Z","iopub.execute_input":"2024-07-08T17:10:01.503787Z","iopub.status.idle":"2024-07-08T17:10:01.584666Z","shell.execute_reply.started":"2024-07-08T17:10:01.503758Z","shell.execute_reply":"2024-07-08T17:10:01.583135Z"},"trusted":true},"execution_count":78,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[78], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m encoder \u001b[38;5;241m=\u001b[39m \u001b[43mTransformerEncoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m48\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m encoder\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      4\u001b[0m encoder(torch\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m100\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong), valid_lens)\u001b[38;5;241m.\u001b[39mshape\n","Cell \u001b[0;32mIn[77], line 14\u001b[0m, in \u001b[0;36mTransformerEncoder.__init__\u001b[0;34m(self, vocab_size, key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, num_layers, dropout, use_bias, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblks \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_layers):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblks\u001b[38;5;241m.\u001b[39madd_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i),\n\u001b[0;32m---> 14\u001b[0m         \u001b[43mEncoderBlock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_hiddens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mnorm_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mffn_num_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mffn_num_hiddens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_bias\u001b[49m\u001b[43m)\u001b[49m)\n","Cell \u001b[0;32mIn[75], line 8\u001b[0m, in \u001b[0;36mEncoderBlock.__init__\u001b[0;34m(self, key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, dropout, use_bias, **kwargs)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key_size, query_size, value_size, num_hiddens,\n\u001b[1;32m      5\u001b[0m              norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n\u001b[1;32m      6\u001b[0m              dropout, use_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28msuper\u001b[39m(EncoderBlock, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention \u001b[38;5;241m=\u001b[39m \u001b[43md2l\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMultiHeadAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_hiddens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddnorm1 \u001b[38;5;241m=\u001b[39m AddNorm(norm_shape, dropout)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn \u001b[38;5;241m=\u001b[39m PositionWiseFFN(\n\u001b[1;32m     13\u001b[0m         ffn_num_input, ffn_num_hiddens, num_hiddens)\n","\u001b[0;31mTypeError\u001b[0m: MultiHeadAttention.__init__() takes from 4 to 5 positional arguments but 8 were given"],"ename":"TypeError","evalue":"MultiHeadAttention.__init__() takes from 4 to 5 positional arguments but 8 were given","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}