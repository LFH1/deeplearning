{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-24T04:38:10.684013Z","iopub.execute_input":"2024-06-24T04:38:10.684436Z","iopub.status.idle":"2024-06-24T04:38:12.049717Z","shell.execute_reply.started":"2024-06-24T04:38:10.684393Z","shell.execute_reply":"2024-06-24T04:38:12.048426Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn\n\nnet = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))\nX = torch.rand(size=(2, 4))\nnet(X)\nprint(net[2].state_dict())\nprint(type(net[2].bias))\nprint(net[2].bias)\nprint(net[2].bias.data)\nnet[2].weight.grad == None","metadata":{"execution":{"iopub.status.busy":"2024-06-24T05:48:17.356299Z","iopub.execute_input":"2024-06-24T05:48:17.356700Z","iopub.status.idle":"2024-06-24T05:48:21.034552Z","shell.execute_reply.started":"2024-06-24T05:48:17.356666Z","shell.execute_reply":"2024-06-24T05:48:21.033096Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"OrderedDict([('weight', tensor([[ 0.2450, -0.2904,  0.0054,  0.0690, -0.3112, -0.2700,  0.0769, -0.1314]])), ('bias', tensor([-0.3519]))])\n<class 'torch.nn.parameter.Parameter'>\nParameter containing:\ntensor([-0.3519], requires_grad=True)\ntensor([-0.3519])\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"print(*[(name, param.shape) for name, param in net[0].named_parameters()])\nprint(*[(name, param.shape) for name, param in net.named_parameters()])\nnet.state_dict()['2.bias'].data","metadata":{"execution":{"iopub.status.busy":"2024-06-24T05:48:21.036576Z","iopub.execute_input":"2024-06-24T05:48:21.037062Z","iopub.status.idle":"2024-06-24T05:48:21.050749Z","shell.execute_reply.started":"2024-06-24T05:48:21.037028Z","shell.execute_reply":"2024-06-24T05:48:21.048896Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"('weight', torch.Size([8, 4])) ('bias', torch.Size([8]))\n('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1]))\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"tensor([-0.3519])"},"metadata":{}}]},{"cell_type":"code","source":"def block1():\n    return nn.Sequential(nn.Linear(4, 8), nn.ReLU(),\n                         nn.Linear(8, 4), nn.ReLU())\n\ndef block2():\n    net = nn.Sequential()\n    for i in range(4):\n        # 在这里嵌套\n        net.add_module(f'block {i}', block1())\n    return net\n\nrgnet = nn.Sequential(block2(), nn.Linear(4, 1))\nrgnet(X)","metadata":{"execution":{"iopub.status.busy":"2024-06-24T05:48:24.691630Z","iopub.execute_input":"2024-06-24T05:48:24.692012Z","iopub.status.idle":"2024-06-24T05:48:24.709233Z","shell.execute_reply.started":"2024-06-24T05:48:24.691982Z","shell.execute_reply":"2024-06-24T05:48:24.708067Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"tensor([[-0.0094],\n        [-0.0094]], grad_fn=<AddmmBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"print(rgnet)","metadata":{"execution":{"iopub.status.busy":"2024-06-24T05:48:28.354133Z","iopub.execute_input":"2024-06-24T05:48:28.354564Z","iopub.status.idle":"2024-06-24T05:48:28.360646Z","shell.execute_reply.started":"2024-06-24T05:48:28.354530Z","shell.execute_reply":"2024-06-24T05:48:28.359294Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Sequential(\n  (0): Sequential(\n    (block 0): Sequential(\n      (0): Linear(in_features=4, out_features=8, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=8, out_features=4, bias=True)\n      (3): ReLU()\n    )\n    (block 1): Sequential(\n      (0): Linear(in_features=4, out_features=8, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=8, out_features=4, bias=True)\n      (3): ReLU()\n    )\n    (block 2): Sequential(\n      (0): Linear(in_features=4, out_features=8, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=8, out_features=4, bias=True)\n      (3): ReLU()\n    )\n    (block 3): Sequential(\n      (0): Linear(in_features=4, out_features=8, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=8, out_features=4, bias=True)\n      (3): ReLU()\n    )\n  )\n  (1): Linear(in_features=4, out_features=1, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"rgnet[0][1][0].bias.data","metadata":{"execution":{"iopub.status.busy":"2024-06-24T05:48:31.602996Z","iopub.execute_input":"2024-06-24T05:48:31.603639Z","iopub.status.idle":"2024-06-24T05:48:31.613825Z","shell.execute_reply.started":"2024-06-24T05:48:31.603599Z","shell.execute_reply":"2024-06-24T05:48:31.612306Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"tensor([-0.4166, -0.2984, -0.1009,  0.0352,  0.4246,  0.4361,  0.4961, -0.3004])"},"metadata":{}}]},{"cell_type":"code","source":"def init_normal(m):\n    if type(m) == nn.Linear:\n        nn.init.normal_(m.weight, mean=0, std=0.01)\n        nn.init.zeros_(m.bias)\nnet.apply(init_normal)\nnet[0].weight.data[0], net[0].bias.data[0]\ndef init_constant(m):\n    if type(m) == nn.Linear:\n        nn.init.constant_(m.weight, 1)\n        nn.init.zeros_(m.bias)\nnet.apply(init_constant)\nnet[0].weight.data[0], net[0].bias.data[0]\ndef init_xavier(m):\n    if type(m) == nn.Linear:\n        nn.init.xavier_uniform_(m.weight)\ndef init_42(m):\n    if type(m) == nn.Linear:\n        nn.init.constant_(m.weight, 42)\n\nnet[0].apply(init_xavier)\nnet[2].apply(init_42)\nprint(net[0].weight.data[0])\nprint(net[2].weight.data)","metadata":{"execution":{"iopub.status.busy":"2024-06-24T05:49:13.821165Z","iopub.execute_input":"2024-06-24T05:49:13.821659Z","iopub.status.idle":"2024-06-24T05:49:13.838311Z","shell.execute_reply.started":"2024-06-24T05:49:13.821626Z","shell.execute_reply":"2024-06-24T05:49:13.836491Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"tensor([-0.4536,  0.5253,  0.1540,  0.3075])\ntensor([[42., 42., 42., 42., 42., 42., 42., 42.]])\n","output_type":"stream"}]},{"cell_type":"code","source":"def my_init(m):\n    if type(m) == nn.Linear:\n        print(\"Init\", *[(name, param.shape)\n                        for name, param in m.named_parameters()][0])\n        nn.init.uniform_(m.weight, -10, 10)\n        m.weight.data *= m.weight.data.abs() >= 5\n\nnet.apply(my_init)\nnet[0].weight[:2]","metadata":{"execution":{"iopub.status.busy":"2024-06-24T05:51:35.362894Z","iopub.execute_input":"2024-06-24T05:51:35.363310Z","iopub.status.idle":"2024-06-24T05:51:35.382769Z","shell.execute_reply.started":"2024-06-24T05:51:35.363278Z","shell.execute_reply":"2024-06-24T05:51:35.381546Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Init weight torch.Size([8, 4])\nInit weight torch.Size([1, 8])\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"tensor([[-0.0000,  5.6391, -0.0000, -0.0000],\n        [-0.0000,  0.0000,  9.3354, -5.1444]], grad_fn=<SliceBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"net[0].weight.data[:] += 1\nnet[0].weight.data[0, 0] = 42\nnet[0].weight.data[0]","metadata":{"execution":{"iopub.status.busy":"2024-06-24T05:52:16.168084Z","iopub.execute_input":"2024-06-24T05:52:16.168550Z","iopub.status.idle":"2024-06-24T05:52:16.180629Z","shell.execute_reply.started":"2024-06-24T05:52:16.168518Z","shell.execute_reply":"2024-06-24T05:52:16.178979Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"tensor([42.0000,  6.6391,  1.0000,  1.0000])"},"metadata":{}}]},{"cell_type":"code","source":"# 我们需要给共享层一个名称，以便可以引用它的参数\nshared = nn.Linear(8, 8)\nnet = nn.Sequential(nn.Linear(4, 8), nn.ReLU(),\n                    shared, nn.ReLU(),\n                    shared, nn.ReLU(),\n                    nn.Linear(8, 1))\nnet(X)\n# 检查参数是否相同\nprint(net[2].weight.data[0] == net[4].weight.data[0])\nnet[2].weight.data[0, 0] = 100\n# 确保它们实际上是同一个对象，而不只是有相同的值\nprint(net[2].weight.data[0] == net[4].weight.data[0])","metadata":{"execution":{"iopub.status.busy":"2024-06-24T05:53:14.863552Z","iopub.execute_input":"2024-06-24T05:53:14.864012Z","iopub.status.idle":"2024-06-24T05:53:14.877078Z","shell.execute_reply.started":"2024-06-24T05:53:14.863976Z","shell.execute_reply":"2024-06-24T05:53:14.875777Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"tensor([True, True, True, True, True, True, True, True])\ntensor([True, True, True, True, True, True, True, True])\n","output_type":"stream"}]},{"cell_type":"code","source":"class FixedHiddenMLP(nn.Module):\n    def __init__(self):\n        super().__init__()\n        # 不计算梯度的随机权重参数。因此其在训练期间保持不变\n        self.rand_weight = torch.rand((20, 20), requires_grad=False)\n        self.linear = nn.Linear(20, 20)\n\n    def forward(self, X):\n        X = self.linear(X)\n        # 使用创建的常量参数以及relu和mm函数\n        X = F.relu(torch.mm(X, self.rand_weight) + 1)\n        # 复用全连接层。这相当于两个全连接层共享参数\n        X = self.linear(X)\n        # 控制流\n        while X.abs().sum() > 1:\n            X /= 2\n        return X.sum()\n\nnet = FixedHiddenMLP()\nfor name, param in net.named_parameters():\n    print(name, param.shape)    ","metadata":{"execution":{"iopub.status.busy":"2024-06-24T06:20:36.395136Z","iopub.execute_input":"2024-06-24T06:20:36.395595Z","iopub.status.idle":"2024-06-24T06:20:36.408315Z","shell.execute_reply.started":"2024-06-24T06:20:36.395559Z","shell.execute_reply":"2024-06-24T06:20:36.406794Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"linear.weight torch.Size([20, 20])\nlinear.bias torch.Size([20])\n","output_type":"stream"}]}]}