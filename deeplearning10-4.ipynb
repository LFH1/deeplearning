{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-08T15:33:32.966786Z","iopub.execute_input":"2024-07-08T15:33:32.967772Z","iopub.status.idle":"2024-07-08T15:33:34.292870Z","shell.execute_reply.started":"2024-07-08T15:33:32.967734Z","shell.execute_reply":"2024-07-08T15:33:34.291743Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom d2l import torch as d2l","metadata":{"execution":{"iopub.status.busy":"2024-07-08T16:22:56.753096Z","iopub.execute_input":"2024-07-08T16:22:56.755791Z","iopub.status.idle":"2024-07-08T16:22:56.771980Z","shell.execute_reply.started":"2024-07-08T16:22:56.755668Z","shell.execute_reply":"2024-07-08T16:22:56.770391Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"#@save\nclass AttentionDecoder(d2l.Decoder):\n    \"\"\"带有注意力机制解码器的基本接口\"\"\"\n    def __init__(self, **kwargs):\n        super(AttentionDecoder, self).__init__(**kwargs)\n\n    @property\n    def attention_weights(self):\n        raise NotImplementedError","metadata":{"execution":{"iopub.status.busy":"2024-07-08T16:23:56.945208Z","iopub.execute_input":"2024-07-08T16:23:56.945788Z","iopub.status.idle":"2024-07-08T16:23:56.954558Z","shell.execute_reply.started":"2024-07-08T16:23:56.945748Z","shell.execute_reply":"2024-07-08T16:23:56.953026Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"class Seq2SeqAttentionDecoder(AttentionDecoder):\n    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n                 dropout=0, **kwargs):\n        super(Seq2SeqAttentionDecoder, self).__init__(**kwargs)\n        self.attention = d2l.AdditiveAttention(\n            num_hiddens, num_hiddens, num_hiddens, dropout)\n        self.embedding = nn.Embedding(vocab_size, embed_size)\n        self.rnn = nn.GRU(\n            embed_size + num_hiddens, num_hiddens, num_layers,\n            dropout=dropout)\n        self.dense = nn.Linear(num_hiddens, vocab_size)\n\n    def init_state(self, enc_outputs, enc_valid_lens, *args):\n        # outputs的形状为(batch_size，num_steps，num_hiddens).\n        # hidden_state的形状为(num_layers，batch_size，num_hiddens)\n        outputs, hidden_state = enc_outputs\n        return (outputs.permute(1, 0, 2), hidden_state, enc_valid_lens)\n\n    def forward(self, X, state):\n        # enc_outputs的形状为(batch_size,num_steps,num_hiddens).\n        # hidden_state的形状为(num_layers,batch_size,\n        # num_hiddens)\n        enc_outputs, hidden_state, enc_valid_lens = state\n        # 输出X的形状为(num_steps,batch_size,embed_size)\n        X = self.embedding(X).permute(1, 0, 2)\n        outputs, self._attention_weights = [], []\n        for x in X:\n            # query的形状为(batch_size,1,num_hiddens)\n            query = torch.unsqueeze(hidden_state[-1], dim=1)\n            # context的形状为(batch_size,1,num_hiddens)\n            context = self.attention(\n                query, enc_outputs, enc_outputs, enc_valid_lens)\n            # 在特征维度上连结\n            x = torch.cat((context, torch.unsqueeze(x, dim=1)), dim=-1)\n            # 将x变形为(1,batch_size,embed_size+num_hiddens)\n            out, hidden_state = self.rnn(x.permute(1, 0, 2), hidden_state)\n            outputs.append(out)\n            self._attention_weights.append(self.attention.attention_weights)\n        # 全连接层变换后，outputs的形状为\n        # (num_steps,batch_size,vocab_size)\n        outputs = self.dense(torch.cat(outputs, dim=0))\n        return outputs.permute(1, 0, 2), [enc_outputs, hidden_state,\n                                          enc_valid_lens]\n\n    @property\n    def attention_weights(self):\n        return self._attention_weights","metadata":{"execution":{"iopub.status.busy":"2024-07-08T16:23:59.285024Z","iopub.execute_input":"2024-07-08T16:23:59.285698Z","iopub.status.idle":"2024-07-08T16:23:59.299449Z","shell.execute_reply.started":"2024-07-08T16:23:59.285647Z","shell.execute_reply":"2024-07-08T16:23:59.297349Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"encoder = d2l.Seq2SeqEncoder(vocab_size=10, embed_size=8, num_hiddens=16,\n                             num_layers=2)\nencoder.eval()\ndecoder = Seq2SeqAttentionDecoder(vocab_size=10, embed_size=8, num_hiddens=16,\n                                  num_layers=2)\ndecoder.eval()\nX = torch.zeros((4, 7), dtype=torch.long)  # (batch_size,num_steps)\nstate = decoder.init_state(encoder(X), None)\noutput, state = decoder(X, state)\noutput.shape, len(state), state[0].shape, len(state[1]), state[1][0].shape","metadata":{"execution":{"iopub.status.busy":"2024-07-08T16:24:02.129754Z","iopub.execute_input":"2024-07-08T16:24:02.130166Z","iopub.status.idle":"2024-07-08T16:24:02.196985Z","shell.execute_reply.started":"2024-07-08T16:24:02.130135Z","shell.execute_reply":"2024-07-08T16:24:02.194732Z"},"trusted":true},"execution_count":53,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[53], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m encoder \u001b[38;5;241m=\u001b[39m d2l\u001b[38;5;241m.\u001b[39mSeq2SeqEncoder(vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, embed_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, num_hiddens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[1;32m      2\u001b[0m                              num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      3\u001b[0m encoder\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m----> 4\u001b[0m decoder \u001b[38;5;241m=\u001b[39m \u001b[43mSeq2SeqAttentionDecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_hiddens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m decoder\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      7\u001b[0m X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m7\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)  \u001b[38;5;66;03m# (batch_size,num_steps)\u001b[39;00m\n","Cell \u001b[0;32mIn[52], line 5\u001b[0m, in \u001b[0;36mSeq2SeqAttentionDecoder.__init__\u001b[0;34m(self, vocab_size, embed_size, num_hiddens, num_layers, dropout, **kwargs)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, vocab_size, embed_size, num_hiddens, num_layers,\n\u001b[1;32m      3\u001b[0m              dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28msuper\u001b[39m(Seq2SeqAttentionDecoder, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention \u001b[38;5;241m=\u001b[39m \u001b[43md2l\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdditiveAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_hiddens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_hiddens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_hiddens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding(vocab_size, embed_size)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mGRU(\n\u001b[1;32m      9\u001b[0m         embed_size \u001b[38;5;241m+\u001b[39m num_hiddens, num_hiddens, num_layers,\n\u001b[1;32m     10\u001b[0m         dropout\u001b[38;5;241m=\u001b[39mdropout)\n","\u001b[0;31mTypeError\u001b[0m: AdditiveAttention.__init__() takes 3 positional arguments but 5 were given"],"ename":"TypeError","evalue":"AdditiveAttention.__init__() takes 3 positional arguments but 5 were given","output_type":"error"}]},{"cell_type":"code","source":"embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.1\nbatch_size, num_steps = 64, 10\nlr, num_epochs, device = 0.005, 250, d2l.try_gpu()\n\ntrain_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(batch_size, num_steps)\nencoder = d2l.Seq2SeqEncoder(\n    len(src_vocab), embed_size, num_hiddens, num_layers, dropout)\ndecoder = Seq2SeqAttentionDecoder(\n    len(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)\nnet = d2l.EncoderDecoder(encoder, decoder)\nd2l.train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T16:24:34.481442Z","iopub.execute_input":"2024-07-08T16:24:34.481851Z","iopub.status.idle":"2024-07-08T16:24:42.496687Z","shell.execute_reply.started":"2024-07-08T16:24:34.481821Z","shell.execute_reply":"2024-07-08T16:24:42.495100Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Downloading ../data/fra-eng.zip from http://d2l-data.s3-accelerate.amazonaws.com/fra-eng.zip...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[54], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m train_iter, src_vocab, tgt_vocab \u001b[38;5;241m=\u001b[39m d2l\u001b[38;5;241m.\u001b[39mload_data_nmt(batch_size, num_steps)\n\u001b[1;32m      6\u001b[0m encoder \u001b[38;5;241m=\u001b[39m d2l\u001b[38;5;241m.\u001b[39mSeq2SeqEncoder(\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mlen\u001b[39m(src_vocab), embed_size, num_hiddens, num_layers, dropout)\n\u001b[0;32m----> 8\u001b[0m decoder \u001b[38;5;241m=\u001b[39m \u001b[43mSeq2SeqAttentionDecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtgt_vocab\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_hiddens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m net \u001b[38;5;241m=\u001b[39m d2l\u001b[38;5;241m.\u001b[39mEncoderDecoder(encoder, decoder)\n\u001b[1;32m     11\u001b[0m d2l\u001b[38;5;241m.\u001b[39mtrain_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)\n","Cell \u001b[0;32mIn[52], line 5\u001b[0m, in \u001b[0;36mSeq2SeqAttentionDecoder.__init__\u001b[0;34m(self, vocab_size, embed_size, num_hiddens, num_layers, dropout, **kwargs)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, vocab_size, embed_size, num_hiddens, num_layers,\n\u001b[1;32m      3\u001b[0m              dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28msuper\u001b[39m(Seq2SeqAttentionDecoder, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention \u001b[38;5;241m=\u001b[39m \u001b[43md2l\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdditiveAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_hiddens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_hiddens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_hiddens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding(vocab_size, embed_size)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mGRU(\n\u001b[1;32m      9\u001b[0m         embed_size \u001b[38;5;241m+\u001b[39m num_hiddens, num_hiddens, num_layers,\n\u001b[1;32m     10\u001b[0m         dropout\u001b[38;5;241m=\u001b[39mdropout)\n","\u001b[0;31mTypeError\u001b[0m: AdditiveAttention.__init__() takes 3 positional arguments but 5 were given"],"ename":"TypeError","evalue":"AdditiveAttention.__init__() takes 3 positional arguments but 5 were given","output_type":"error"}]}]}